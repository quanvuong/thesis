\BOOKMARK [0][-]{section*.1}{Dissertation Approval Page}{}% 1
\BOOKMARK [0][-]{section*.2}{Dedication}{}% 2
\BOOKMARK [0][-]{section*.3}{Table of Contents}{}% 3
\BOOKMARK [0][-]{section*.4}{List of Figures}{}% 4
\BOOKMARK [0][-]{section*.5}{List of Tables}{}% 5
\BOOKMARK [0][-]{section*.6}{Vita}{}% 6
\BOOKMARK [0][-]{section*.7}{Abstract of the Dissertation}{}% 7
\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 8
\BOOKMARK [1][-]{section.1.1}{Algorithms for offline and online Reinforcement Learning}{chapter.1}% 9
\BOOKMARK [1][-]{section.1.2}{Teleoperation system}{chapter.1}% 10
\BOOKMARK [1][-]{section.1.3}{Real2Sim2Real}{chapter.1}% 11
\BOOKMARK [0][-]{chapter.2}{Multi-task Batch Reinforcement Learning with Metric Learning}{}% 12
\BOOKMARK [1][-]{section.2.1}{Preliminaries and Problem Statement}{chapter.2}% 13
\BOOKMARK [2][-]{subsection.2.1.1}{Batch Reinforcement Learning}{section.2.1}% 14
\BOOKMARK [2][-]{subsection.2.1.2}{Multi-task Batch Reinforcement Learning}{section.2.1}% 15
\BOOKMARK [1][-]{section.2.2}{Proposed algorithm}{chapter.2}% 16
\BOOKMARK [2][-]{subsection.2.2.1}{Learning multi-task policy from offline data with distillation}{section.2.2}% 17
\BOOKMARK [2][-]{subsection.2.2.2}{Robust task inference with triplet loss design}{section.2.2}% 18
\BOOKMARK [1][-]{section.2.3}{Experiment Results}{chapter.2}% 19
\BOOKMARK [2][-]{subsection.2.3.1}{Performance evaluation on unseen tasks}{section.2.3}% 20
\BOOKMARK [2][-]{subsection.2.3.2}{Ablations}{section.2.3}% 21
\BOOKMARK [2][-]{subsection.2.3.3}{Using the multi-task policy to enable faster convergence when training on unseen tasks}{section.2.3}% 22
\BOOKMARK [1][-]{section.2.4}{Related Works}{chapter.2}% 23
\BOOKMARK [1][-]{section.2.5}{Discussions}{chapter.2}% 24
\BOOKMARK [0][-]{chapter*.17}{Bibliography}{}% 25
